{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiranjit680/Saahaita/blob/main/SaahaitaModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqv9B5zph4rV",
        "outputId": "11c6cd08-b4a8-4ebc-e4d2-12fcb2bdd8da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\CHIRANJIT\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\CHIRANJIT\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKkrYGkuiKJe"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('tweets_tokenized.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ8UrCzbibbf"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, df, min_freq=2, tokenizer=word_tokenize):\n",
        "        self.min_freq = min_freq\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.word2index = {'<unk>': 0}\n",
        "\n",
        "    def build_vocabulary(self):\n",
        "        # Apply tokenizer to every text row after ensuring it is a string\n",
        "        self.df[\"tokens\"] = self.df[\"text\"].astype(str).apply(self.tokenizer)\n",
        "\n",
        "        word_freq = {}\n",
        "\n",
        "        for tokens in self.df[\"tokens\"]:\n",
        "            for word in tokens:\n",
        "                word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "        index = 1  # starting index after <unk>\n",
        "        for word, freq in word_freq.items():\n",
        "            if freq >= self.min_freq:\n",
        "                self.word2index[word] = index\n",
        "                index += 1\n",
        "\n",
        "        return self.word2index\n",
        "\n",
        "    def vectorize_dataframe(self):\n",
        "        vocab = self.build_vocabulary()\n",
        "\n",
        "        def vectorize(tokens):\n",
        "            return [vocab.get(token, 0) for token in tokens]  # 0 = <unk>\n",
        "\n",
        "        self.df[\"numerical_text\"] = self.df[\"tokens\"].apply(vectorize)\n",
        "\n",
        "        return self.df\n",
        "    def zero_padding(self):\n",
        "      max_len=max(len(x) for x in self.df['numerical_text'])\n",
        "      self.df['numerical_text']=self.df['numerical_text'].apply(lambda x:x+[0]*(max_len-len(x)))\n",
        "      return self.df\n",
        "    def get_vocab_size(self):\n",
        "      return len(self.word2index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTcJYzaVieec"
      },
      "outputs": [],
      "source": [
        "vocab_builder=Vocabulary(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "yUb296DymdJn",
        "outputId": "713dd738-6494-4d6b-92c0-baed463e46a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>disaster_category</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>numerical_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>communal violence bhainsa telangana stone pelt...</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[communal, violence, bhainsa, telangana, stone...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>telangana section imposed bhainsa january clas...</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[telangana, section, imposed, bhainsa, january...</td>\n",
              "      <td>[4, 12, 13, 3, 14, 15, 16, 17, 18, 14, 19, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arsonist set car ablaze dealership</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[arsonist, set, car, ablaze, dealership]</td>\n",
              "      <td>[20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>arsonist set car ablaze dealership</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[arsonist, set, car, ablaze, dealership]</td>\n",
              "      <td>[20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lord jesus love brings freedom pardon fill hol...</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[lord, jesus, love, brings, freedom, pardon, f...</td>\n",
              "      <td>[23, 24, 25, 26, 27, 0, 28, 29, 30, 10, 31, 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9546</th>\n",
              "      <td>medium warned u well advance wrecked whole nig...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[medium, warned, u, well, advance, wrecked, wh...</td>\n",
              "      <td>[40, 4410, 238, 538, 2548, 5771, 110, 55, 3870...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9547</th>\n",
              "      <td>feel directly attacked consider moonbin amp ji...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[feel, directly, attacked, consider, moonbin, ...</td>\n",
              "      <td>[497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9548</th>\n",
              "      <td>feel directly attacked consider moonbin amp ji...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[feel, directly, attacked, consider, moonbin, ...</td>\n",
              "      <td>[497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9549</th>\n",
              "      <td>ok remember outcast nd dora au au wrecked nerv...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[ok, remember, outcast, nd, dora, au, au, wrec...</td>\n",
              "      <td>[730, 878, 1546, 3646, 0, 1190, 1190, 5771, 70...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9550</th>\n",
              "      <td>jake corway wrecked running th irp</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[jake, corway, wrecked, running, th, irp]</td>\n",
              "      <td>[0, 0, 5771, 567, 186, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9551 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text disaster_category  \\\n",
              "0     communal violence bhainsa telangana stone pelt...             Fires   \n",
              "1     telangana section imposed bhainsa january clas...             Fires   \n",
              "2                    arsonist set car ablaze dealership             Fires   \n",
              "3                    arsonist set car ablaze dealership             Fires   \n",
              "4     lord jesus love brings freedom pardon fill hol...             Fires   \n",
              "...                                                 ...               ...   \n",
              "9546  medium warned u well advance wrecked whole nig...        Explosions   \n",
              "9547  feel directly attacked consider moonbin amp ji...        Explosions   \n",
              "9548  feel directly attacked consider moonbin amp ji...        Explosions   \n",
              "9549  ok remember outcast nd dora au au wrecked nerv...        Explosions   \n",
              "9550                 jake corway wrecked running th irp        Explosions   \n",
              "\n",
              "      label                                             tokens  \\\n",
              "0         3  [communal, violence, bhainsa, telangana, stone...   \n",
              "1         3  [telangana, section, imposed, bhainsa, january...   \n",
              "2         3           [arsonist, set, car, ablaze, dealership]   \n",
              "3         3           [arsonist, set, car, ablaze, dealership]   \n",
              "4         3  [lord, jesus, love, brings, freedom, pardon, f...   \n",
              "...     ...                                                ...   \n",
              "9546      2  [medium, warned, u, well, advance, wrecked, wh...   \n",
              "9547      2  [feel, directly, attacked, consider, moonbin, ...   \n",
              "9548      2  [feel, directly, attacked, consider, moonbin, ...   \n",
              "9549      2  [ok, remember, outcast, nd, dora, au, au, wrec...   \n",
              "9550      2          [jake, corway, wrecked, running, th, irp]   \n",
              "\n",
              "                                         numerical_text  \n",
              "0     [1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 0, 0, 0...  \n",
              "1     [4, 12, 13, 3, 14, 15, 16, 17, 18, 14, 19, 0, ...  \n",
              "2     [20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
              "3     [20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
              "4     [23, 24, 25, 26, 27, 0, 28, 29, 30, 10, 31, 11...  \n",
              "...                                                 ...  \n",
              "9546  [40, 4410, 238, 538, 2548, 5771, 110, 55, 3870...  \n",
              "9547  [497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...  \n",
              "9548  [497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...  \n",
              "9549  [730, 878, 1546, 3646, 0, 1190, 1190, 5771, 70...  \n",
              "9550  [0, 0, 5771, 567, 186, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
              "\n",
              "[9551 rows x 5 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab=vocab_builder.build_vocabulary()\n",
        "vocab_builder.vectorize_dataframe()\n",
        "vocab_builder.zero_padding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "wAk8ZxL6m4SU",
        "outputId": "22200555-46ca-4e93-b67e-0e845bbcd11a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>disaster_category</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>numerical_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>communal violence bhainsa telangana stone pelt...</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[communal, violence, bhainsa, telangana, stone...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>telangana section imposed bhainsa january clas...</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[telangana, section, imposed, bhainsa, january...</td>\n",
              "      <td>[4, 12, 13, 3, 14, 15, 16, 17, 18, 14, 19, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arsonist set car ablaze dealership</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[arsonist, set, car, ablaze, dealership]</td>\n",
              "      <td>[20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>arsonist set car ablaze dealership</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[arsonist, set, car, ablaze, dealership]</td>\n",
              "      <td>[20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lord jesus love brings freedom pardon fill hol...</td>\n",
              "      <td>Fires</td>\n",
              "      <td>3</td>\n",
              "      <td>[lord, jesus, love, brings, freedom, pardon, f...</td>\n",
              "      <td>[23, 24, 25, 26, 27, 0, 28, 29, 30, 10, 31, 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9546</th>\n",
              "      <td>medium warned u well advance wrecked whole nig...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[medium, warned, u, well, advance, wrecked, wh...</td>\n",
              "      <td>[40, 4410, 238, 538, 2548, 5771, 110, 55, 3870...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9547</th>\n",
              "      <td>feel directly attacked consider moonbin amp ji...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[feel, directly, attacked, consider, moonbin, ...</td>\n",
              "      <td>[497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9548</th>\n",
              "      <td>feel directly attacked consider moonbin amp ji...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[feel, directly, attacked, consider, moonbin, ...</td>\n",
              "      <td>[497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9549</th>\n",
              "      <td>ok remember outcast nd dora au au wrecked nerv...</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[ok, remember, outcast, nd, dora, au, au, wrec...</td>\n",
              "      <td>[730, 878, 1546, 3646, 0, 1190, 1190, 5771, 70...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9550</th>\n",
              "      <td>jake corway wrecked running th irp</td>\n",
              "      <td>Explosions</td>\n",
              "      <td>2</td>\n",
              "      <td>[jake, corway, wrecked, running, th, irp]</td>\n",
              "      <td>[0, 0, 5771, 567, 186, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9551 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text disaster_category  \\\n",
              "0     communal violence bhainsa telangana stone pelt...             Fires   \n",
              "1     telangana section imposed bhainsa january clas...             Fires   \n",
              "2                    arsonist set car ablaze dealership             Fires   \n",
              "3                    arsonist set car ablaze dealership             Fires   \n",
              "4     lord jesus love brings freedom pardon fill hol...             Fires   \n",
              "...                                                 ...               ...   \n",
              "9546  medium warned u well advance wrecked whole nig...        Explosions   \n",
              "9547  feel directly attacked consider moonbin amp ji...        Explosions   \n",
              "9548  feel directly attacked consider moonbin amp ji...        Explosions   \n",
              "9549  ok remember outcast nd dora au au wrecked nerv...        Explosions   \n",
              "9550                 jake corway wrecked running th irp        Explosions   \n",
              "\n",
              "      label                                             tokens  \\\n",
              "0         3  [communal, violence, bhainsa, telangana, stone...   \n",
              "1         3  [telangana, section, imposed, bhainsa, january...   \n",
              "2         3           [arsonist, set, car, ablaze, dealership]   \n",
              "3         3           [arsonist, set, car, ablaze, dealership]   \n",
              "4         3  [lord, jesus, love, brings, freedom, pardon, f...   \n",
              "...     ...                                                ...   \n",
              "9546      2  [medium, warned, u, well, advance, wrecked, wh...   \n",
              "9547      2  [feel, directly, attacked, consider, moonbin, ...   \n",
              "9548      2  [feel, directly, attacked, consider, moonbin, ...   \n",
              "9549      2  [ok, remember, outcast, nd, dora, au, au, wrec...   \n",
              "9550      2          [jake, corway, wrecked, running, th, irp]   \n",
              "\n",
              "                                         numerical_text  \n",
              "0     [1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 0, 0, 0...  \n",
              "1     [4, 12, 13, 3, 14, 15, 16, 17, 18, 14, 19, 0, ...  \n",
              "2     [20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
              "3     [20, 10, 21, 11, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
              "4     [23, 24, 25, 26, 27, 0, 28, 29, 30, 10, 31, 11...  \n",
              "...                                                 ...  \n",
              "9546  [40, 4410, 238, 538, 2548, 5771, 110, 55, 3870...  \n",
              "9547  [497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...  \n",
              "9548  [497, 3303, 1937, 774, 7872, 105, 7887, 1272, ...  \n",
              "9549  [730, 878, 1546, 3646, 0, 1190, 1190, 5771, 70...  \n",
              "9550  [0, 0, 5771, 567, 186, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
              "\n",
              "[9551 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRVTo0jCo1ix"
      },
      "outputs": [],
      "source": [
        "X=df['numerical_text']\n",
        "y=df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA9w8je5rKKN"
      },
      "outputs": [],
      "source": [
        "X=torch.tensor(X.tolist())\n",
        "y=torch.tensor(y.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK4AfGCRo38I"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zzBKWllrQB1",
        "outputId": "aaebdb4b-4aee-400c-b971-57c1685646cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrtDzutDqq9v"
      },
      "outputs": [],
      "source": [
        "vocab_size=vocab_builder.get_vocab_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUamKGwGqy6G",
        "outputId": "0450c414-9fd3-422a-aa36-ede8d15a0b86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7888"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_leuz_uq0_i"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, labels):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index], self.labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAQlsc5Cq_kl"
      },
      "outputs": [],
      "source": [
        "dataset=CustomDataset(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc4cQqrGrZzu"
      },
      "outputs": [],
      "source": [
        "dataloader=DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0es0kj7rpGr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size=26, embedding_dim=256, hidden_dim=512, output_dim=10, n_layers=4, bidirectional=False, dropout=0.15, pad_idx=0):\n",
        "        super().__init__()\n",
        "        self.bidirectional =bidirectional  # Store bidirectional as instance variable\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0)\n",
        "        self.attention=nn.MultiheadAttention(hidden_dim, 4, dropout=dropout)\n",
        "        self.fc= nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, hidden_dim // 2),\n",
        "            nn.BatchNorm1d(hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
        "            nn.BatchNorm1d(hidden_dim // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 4, output_dim)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        lstm_out, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            hidden = hidden[-1]\n",
        "\n",
        "        # Fix attention mechanism - all inputs should have same dimensions\n",
        "        attn_input = lstm_out.transpose(0, 1)  # [seq_len, batch, hidden_dim]\n",
        "        attn_out, _ = self.attention(attn_input, attn_input, attn_input)\n",
        "        attn_out = attn_out.transpose(0, 1)  # [batch, seq_len, hidden_dim]\n",
        "\n",
        "        # Global max pooling over sequence dimension\n",
        "        out = torch.max(attn_out, dim=1)[0]  # [batch, hidden_dim]\n",
        "        output = self.fc(out)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odt663Y8t_6V"
      },
      "outputs": [],
      "source": [
        "model=LSTMModel(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGtwtMWkuOFz"
      },
      "outputs": [],
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWUrbgN_uRVi",
        "outputId": "8bce6e9c-60ea-4ff0-eda3-68427d0602bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(7888, 256, padding_idx=0)\n",
              "  (rnn): LSTM(256, 512, num_layers=4, batch_first=True, dropout=0.15)\n",
              "  (attention): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.15, inplace=False)\n",
              "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU()\n",
              "    (4): Dropout(p=0.075, inplace=False)\n",
              "    (5): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.15, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHM_HE7MuTcq",
        "outputId": "7bdaafb2-0707-410d-c75d-eb4fb4183468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 : 1141\n",
            "0 : 1144\n",
            "5 : 1536\n",
            "4 : 1671\n",
            "2 : 1127\n",
            "8 : 1453\n",
            "6 : 312\n",
            "9 : 70\n",
            "1 : 883\n",
            "7 : 214\n"
          ]
        }
      ],
      "source": [
        "for label in df['label'].unique():\n",
        "  print(label,\":\",(df['label']==label).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPuNssALu56L"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def setup_training(model, learning_rate=0.01):\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "    classes = torch.unique(y_train).numpy()\n",
        "    class_weights = compute_class_weight('balanced', classes=classes, y=y_train.numpy())\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
        "    )\n",
        "\n",
        "    return optimizer, criterion, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJfwlUt0vL8n"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion, scheduler, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Ensure training mode\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for data, labels in dataloader:\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        train_accuracy = correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "        scheduler.step(avg_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "TyTY7xlrv7i7",
        "outputId": "37e8f3ec-dc47-47b0-c9cd-8b26726f4856"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\CHIRANJIT\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msetup_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[32], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, scheduler, epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\CHIRANJIT\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\CHIRANJIT\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\CHIRANJIT\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(model, dataloader, *setup_training(model), epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNqWyNqAv9EV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import numpy as np\n",
        "def evaluate_model(model, test_loader, criterion=None, device='cpu'):\n",
        "    \"\"\"\n",
        "    Evaluate the LSTM model on test data\n",
        "\n",
        "    Args:\n",
        "        model: Trained LSTM model\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function (optional)\n",
        "        device: Device to run evaluation on\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, targets) in enumerate(test_loader):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(data)\n",
        "\n",
        "            # Calculate loss if criterion provided\n",
        "            if criterion is not None:\n",
        "                loss = criterion(outputs, targets)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_true_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_true_labels = np.array(all_true_labels)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        all_true_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'confusion_matrix': cm,\n",
        "        'average_loss': total_loss / len(test_loader) if criterion is not None else None\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "PGy0jnY7w3Ya",
        "outputId": "5b183c18-649a-4e31-c34a-054ec7c22183"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_test_tensor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-80-1264698886.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_tensor' is not defined"
          ]
        }
      ],
      "source": [
        "testloader = DataLoader(CustomDataset(X_test, y_test), batch_size=32, shuffle=False)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "results = evaluate_model(model, testloader, criterion=criterion , device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9ed4-W5w4Co"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluation Results:\")\n",
        "print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
        "print(f\"Precision: {results['precision']:.4f}\")\n",
        "print(f\"Recall: {results['recall']:.4f}\")\n",
        "print(f\"F1 Score: {results['f1_score']:.4f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}